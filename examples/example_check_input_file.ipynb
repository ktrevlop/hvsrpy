{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Compatibility of Input File\n",
    "\n",
    "## License Information\n",
    "\n",
    "This file is part of _hvsrpy_, a Python package for horizontal-to-vertical spectral ratio processing.\n",
    "\n",
    "    Copyright (C) 2019-2025 Joseph P. Vantassel (joseph.p.vantassel@gmail.com)\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.|\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <https: //www.gnu.org/licenses/>.\n",
    "    \n",
    "## About _hvsrpy_\n",
    "\n",
    "_hvsrpy_ is an open-source Python package for performing horizontal-to-vertical spectral ratio (HVSR) processing of microtremor and earthquake recordings. _hvsrpy_ was developed by [Joseph P. Vantassel](https://www.jpvantassel.com/) with contributions from Dana M. Brannon under the supervision of Brady R. Cox at The University of Texas at Austin. _hvsrpy_ continues to be developed and maintained by [Joseph P. Vantassel and his research group at Virginia Tech](https://geoimaging-research.org/).\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use _hvsrpy_ in your research or consulting, we ask you please cite the following:\n",
    "\n",
    "> Vantassel, J.P. (2025). \"_hvsrpy_: An Open‐Source Python Package for Microtremor\n",
    "> and Earthquake Horizontal‐to‐Vertical Spectral Ratio Processing\". Seismological\n",
    "> Research Letters. 96 (4): 2671–2682,\n",
    "> [https://doi.org/10.1785/0220240395](https://doi.org/10.1785/0220240395)\n",
    "\n",
    "> Joseph Vantassel. (2020). jpvantassel/hvsrpy: latest (Concept). Zenodo.\n",
    "> [http://doi.org/10.5281/zenodo.3666956](http://doi.org/10.5281/zenodo.3666956)\n",
    "\n",
    "_For software, version specific citations should be preferred to\n",
    "general concept citations. To generate a version specific citation\n",
    "for `hvsrpy`, please use the citation tool on the `hvsrpy`\n",
    "[archive](http://doi.org/10.5281/zenodo.3666956)._\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook checks an example data file for common formatting issues. If a formatting issue is identified, the notebook suggests how to fix the file so that it can be ready by _hvsrpy_.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. Install _hvsrpy_, with `pip install hvsrpy`. More information on _pip_ can be found [here](https://jpvantassel.github.io/python3-course/#/intro/pip). __(~3 minutes)__\n",
    "2. Run the provided example __(~2 minutes)__\n",
    "3. Swap the provided example with your own. __(~2 minutes)__\n",
    "\n",
    "Happy Processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from termcolor import colored\n",
    "import obspy\n",
    "import hvsrpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "User provided path to the file for processing. The file can be of the following types:\n",
    "- MiniSEED (MSEED)\n",
    "- Guralp Compressed Format (GCF)\n",
    "- Seismic Analysis Code (SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 file(s) names provided:\n",
      "  ./data/UT.STN11.A2_C150.miniseed\n",
      "\u001b[32mAll file(s) exist.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inputs -------------\n",
    "# Option 1: for three-components in a single file\n",
    "fname_set = [\"./data/UT.STN11.A2_C150.miniseed\"]\n",
    "\n",
    "# Option 2: for three, single-component files\n",
    "# fname_set = [f\"./data/453016990.0001.{c}.miniseed\" for c in \"NEZ\"]\n",
    "\n",
    "# --------------------\n",
    "print()\n",
    "print(f\"{len(fname_set)} file(s) names provided:\")\n",
    "for fname in fname_set:\n",
    "    print(f\"  {fname}\")\n",
    "\n",
    "for file in fname_set:\n",
    "    if not pathlib.Path(file).exists():\n",
    "        raise FileNotFoundError(f\"file {file} not found; check spelling.\")\n",
    "print(colored(\"All file(s) exist.\", \"green\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check File Type\n",
    "\n",
    "Check if file can be read by `obspy`. Check to see if any special read arguments (`obspy_read_kwargs`) are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mAll file(s) were able to be read by ObsPy.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inputs -------------\n",
    "obspy_read_kwargs = dict()\n",
    "\n",
    "# --------------------\n",
    "failed = False\n",
    "for file in fname_set:\n",
    "    try:\n",
    "        obspy.read(file, **obspy_read_kwargs)\n",
    "    except Exception:\n",
    "        failed = True\n",
    "        break\n",
    "\n",
    "print()\n",
    "if failed:\n",
    "    print(colored(\"All file(s) were not able to be read by ObsPy.\", \"red\"))\n",
    "    print(\"  1. Check if your file is in MiniSEED, CGF, or SAC format.\")\n",
    "    print(\"  2. Try supplying the file type as part of obspy_read_kwargs, e.g., obspy_read_kwargs = dict(format='MSEED').\")\n",
    "    print(\"  3. Try reading your file with Geopsy (geopsy.org) and export it as MiniSEED.\")\n",
    "else:\n",
    "    print(colored(\"All file(s) were able to be read by ObsPy.\", \"green\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Number of Traces\n",
    "\n",
    "Check if the data provided supplies exactly three traces of data, one for each component of the sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 file(s) names provided:\n",
      "  ./data/UT.STN11.A2_C150.miniseed\n",
      "\u001b[32m    File has 3 components as expected.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "if len(fname_set) == 1:\n",
    "    print(\"1 file(s) names provided:\")\n",
    "    stream = obspy.read(fname_set[0], **obspy_read_kwargs)\n",
    "    print(f\"  {fname_set[0]}\")\n",
    "    if len(stream) != 3:\n",
    "        print(colored(f\"    File must contain 3 traces of data, but {len(stream)} straces were found.\", \"red\"))\n",
    "        print(\"      1. Try removing extra components from ObsPy Stream object.\")\n",
    "        print(\"      2. Try merging together components, e.g., stream.merge()\")\n",
    "    else:\n",
    "        print(colored(f\"    File has 3 components as expected.\", \"green\"))\n",
    "elif len(fname_set) == 3:\n",
    "    print(\"3 file(s) names provided, checking each:\")\n",
    "    for fname in fname_set:\n",
    "        print(f\"  {fname}\")\n",
    "        stream = obspy.read(fname, **obspy_read_kwargs)\n",
    "        if len(stream) != 1:\n",
    "            print(colored(f\"    File must contain 1 traces of data, but {len(stream)} traces were found.\", \"red\"))\n",
    "            print(\"      1. Try removing extra components from ObsPy Stream object.\")\n",
    "            print(\"      2. Try merging together components, e.g., stream.merge()\")\n",
    "        else:\n",
    "            print(colored(f\"    File has 1 component as expected.\", \"green\"))\n",
    "else:\n",
    "    print(colored(f\"You can only provide 1, 3-component file or 3, 1-component file, but {len(fname_set)} were provided.\", \"red\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Component Naming\n",
    "\n",
    "Check each component name is any of the following: NEZ, 123, 12Z, XYZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided components are:\n",
      "  BHN\n",
      "  BHE\n",
      "  BHZ\n",
      "\u001b[32mThe components provided are self-consistent and acceptable.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inputs -------------\n",
    "degrees_from_north = None\n",
    "\n",
    "# --------------------\n",
    "print()\n",
    "if len(fname_set) == 1:\n",
    "    stream = obspy.read(fname_set[0], **obspy_read_kwargs)\n",
    "elif len(fname_set) == 3:\n",
    "    traces = []\n",
    "    for fname in fname_set:\n",
    "        _stream = obspy.read(fname, **obspy_read_kwargs)\n",
    "        if len(_stream) != 1:\n",
    "            raise ValueError(f\"File must contain 1 trace of data, but {len(_stream)} traces were found.\")\n",
    "        traces.append(_stream[0])\n",
    "    stream = obspy.Stream(traces)\n",
    "else:\n",
    "    raise ValueError(f\"You can only provide 1, 3-component file or 3, 1-component file, but {len(fname_set)} were provided.\")\n",
    "\n",
    "try:\n",
    "    hvsrpy.data_wrangler._orient_traces(stream, degrees_from_north)\n",
    "except ValueError:\n",
    "    failed=True\n",
    "else:\n",
    "    failed=False\n",
    "\n",
    "print(\"The provided components are:\")\n",
    "for trace in stream:\n",
    "    print(f\"  {trace.meta.channel}\")\n",
    "if failed:\n",
    "    print(colored(f\"The components provided are not valid:.\", \"red\"))\n",
    "    print(\"  1. If the components end in '123' or '12Z', try providing the sensors orientation using degrees_from_north.\")\n",
    "    print(\"  2. Check that the data are from a three-component sensor.\")\n",
    "    print(\"  3. Try renaming the components such that they end with 'NEZ', '123', '12Z', or 'XYZ'.\")\n",
    "else:\n",
    "    print(colored(f\"The components provided are self-consistent and acceptable.\", \"green\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Start and End Times\n",
    "\n",
    "Check that the traces have an overlapped period of recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The start and end time of each trace in UTC is:\n",
      "  2017-05-04T07:00:00.000000Z - 2017-05-04T08:00:00.000000Z\n",
      "  2017-05-04T07:00:00.000000Z - 2017-05-04T08:00:00.000000Z\n",
      "  2017-05-04T07:00:00.000000Z - 2017-05-04T08:00:00.000000Z\n",
      "\u001b[32m60.0 minutes of three-component data were recorded.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_times_utc = [trace.stats.starttime for trace in stream]\n",
    "end_times_utc = [trace.stats.endtime for trace in stream]\n",
    "\n",
    "print()\n",
    "print(\"The start and end time of each trace in UTC is:\")\n",
    "for start_time, end_time in zip(start_times_utc, end_times_utc):\n",
    "    print(f\"  {start_time} - {end_time}\")\n",
    "\n",
    "duration_in_seconds = min(end_times_utc) - max(start_times_utc)\n",
    "if duration_in_seconds < 0.1:\n",
    "    print(colored(f\"There is no segement where all three components are recording at the same time\", \"red\"))\n",
    "    print(\"  1. Check the start times were correctly recorded by the sensor.\")\n",
    "    print(\"  2. Check the sensor's state-of-health to confirm the sensor was working correctly.\")\n",
    "    print(\"  3. Try a recording from another sensor.\")\n",
    "    print(\"  4. Try a second recording with the same sensor.\")\n",
    "else:\n",
    "    duration_in_minutes = duration_in_seconds/60\n",
    "    print(colored(f\"{duration_in_minutes:.1f} minutes of three-component data were recorded.\", \"green\"))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
